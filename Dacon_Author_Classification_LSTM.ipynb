{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "github.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7r4KYWnYttef"
      },
      "source": [
        "https://dacon.io/competitions/official/235670/codeshare/1771?page=1&dtype=recent&ptype=pub\n",
        "\n",
        "위 코드를 참고하여 데이콘 대회 데이터를 적용해본 NLP 연습\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Njz3FaEuttZ1"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-vu5WN0tHmA"
      },
      "source": [
        "# 작업환경 설정 및 데이터 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNENEq0xQaZV",
        "outputId": "5b5c3e23-febe-46d4-d942-5adf567eb1a1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fGTQqubQYf2"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "np.random.seed(42)\n",
        "import re\n",
        "import os\n",
        "import tqdm\n",
        "\n",
        "import lightgbm as lgbm\n",
        "import xgboost as xgb\n",
        "\n",
        "from scipy import sparse\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, log_loss\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn import ensemble, metrics, model_selection, naive_bayes\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM, GlobalMaxPooling1D, Conv1D, Dropout, Bidirectional\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.utils import plot_model, to_categorical\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "from keras.initializers import Constant\n",
        "\n",
        "import nltk\n",
        "from nltk.tokenize import TreebankWordTokenizer\n",
        "from nltk import FreqDist\n",
        "from nltk.corpus import stopwords \n",
        "from nltk.stem import PorterStemmer\n",
        "import string"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xzNkibyQYf5"
      },
      "source": [
        "train = pd.read_csv('train.csv', encoding = 'utf-8')\n",
        "test = pd.read_csv('test_x.csv', encoding = 'utf-8')\n",
        "sample_submission = pd.read_csv('sample_submission.csv', encoding = 'utf-8')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7EcW2Y7VtPZl"
      },
      "source": [
        "# 전처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VD0-ittqylni"
      },
      "source": [
        "#소문자로 변환\n",
        "train['text'] = train['text'].str.lower()\n",
        "test['text'] = test['text'].str.lower()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "id": "VccRSDZRylni"
      },
      "source": [
        "#일부 접어 전처리\n",
        "def decontraction(text):\n",
        "    text = re.sub(r\"’\", \"\\'\", text)\n",
        "    text = re.sub(r\"won\\'t\", \" will not\", text)\n",
        "    text = re.sub(r\"won\\'t've\", \" will not have\", text)\n",
        "    text = re.sub(r\"can\\'t\", \" can not\", text)\n",
        "    text = re.sub(r\"don\\'t\", \" do not\", text)\n",
        "    text = re.sub(r\"can\\'t've\", \" can not have\", text)\n",
        "    text = re.sub(r\"ma\\'am\", \" madam\", text)\n",
        "    text = re.sub(r\"let\\'s\", \" let us\", text)\n",
        "    text = re.sub(r\"ain\\'t\", \" am not\", text)\n",
        "    text = re.sub(r\"shan\\'t\", \" shall not\", text)\n",
        "    text = re.sub(r\"sha\\n't\", \" shall not\", text)\n",
        "    text = re.sub(r\"o\\'clock\", \" of the clock\", text)\n",
        "    text = re.sub(r\"y\\'all\", \" you all\", text)\n",
        "    text = re.sub(r\"n\\'t\", \" not\", text)\n",
        "    text = re.sub(r\"n\\'t've\", \" not have\", text)\n",
        "    text = re.sub(r\"\\'re\", \" are\", text)\n",
        "    text = re.sub(r\"\\'s\", \" is\", text)\n",
        "    text = re.sub(r\"\\'d\", \" would\", text)\n",
        "    text = re.sub(r\"\\'d've\", \" would have\", text)\n",
        "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
        "    text = re.sub(r\"\\'ll've\", \" will have\", text)\n",
        "    text = re.sub(r\"\\'t\", \" not\", text)\n",
        "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
        "    text = re.sub(r\"\\'m\", \" am\", text)\n",
        "    text = re.sub(r\"\\'re\", \" are\", text)\n",
        "    return text \n",
        "\n",
        "train['text'] = train['text'].apply(decontraction)\n",
        "test['text'] = test['text'].apply(decontraction)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RoSCBFmMylni"
      },
      "source": [
        "#불용어 1차 처리 및 부호 제거\n",
        "def alpha_num(text):\n",
        "    return re.sub(r'[^A-Za-z0-9 ]', '', text)\n",
        "\n",
        "def remove_stopwords(text):\n",
        "    final_text = []\n",
        "    for i in text.split():\n",
        "        if i.strip().lower() not in stopwords_base:\n",
        "            final_text.append(i.strip())\n",
        "    return \" \".join(final_text)\n",
        "\n",
        "\n",
        "stopwords_base = [ \"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"as\", \n",
        "             \"at\", \"be\", \"because\", \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \"could\", \n",
        "             \"did\", \"do\", \"does\", \"doing\", \"down\", \"during\", \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"has\", \n",
        "             \"have\", \"having\", \"he\", \"he'd\", \"he'll\", \"he's\", \"her\", \"here\", \"here's\", \"hers\", \"herself\", \"him\", \"himself\", \n",
        "             \"his\", \"how\", \"how's\", \"i\", \"i'd\", \"i'll\", \"i'm\", \"i've\", \"if\", \"in\", \"into\", \"is\", \"it\", \"it's\", \"its\", \"itself\", \n",
        "             \"let's\", \"me\", \"more\", \"most\", \"my\", \"myself\", \"nor\", \"of\", \"on\", \"once\", \"only\", \"or\", \"other\", \"ought\", \"our\", \"ours\", \n",
        "             \"ourselves\", \"out\", \"over\", \"own\", \"same\", \"she\", \"she'd\", \"she'll\", \"she's\", \"should\", \"so\", \"some\", \"such\", \"than\", \"that\", \n",
        "             \"that's\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"there\", \"there's\", \"these\", \"they\", \"they'd\", \"they'll\", \n",
        "             \"they're\", \"they've\", \"this\", \"those\", \"through\", \"to\", \"too\", \"under\", \"until\", \"up\", \"very\", \"was\", \"we\", \"we'd\", \"we'll\", \n",
        "             \"we're\", \"we've\", \"were\", \"what\", \"what's\", \"when\", \"when's\", \"where\", \"where's\", \"which\", \"while\", \"who\", \"who's\", \"whom\", \n",
        "             \"why\", \"why's\", \"with\", \"would\", \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\", \"your\", \"yours\", \"yourself\", \"yourselves\",\n",
        "             \"odin\", \"said\", \"mr\", \"upon\", \"one\"]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "re_X0FVfylni"
      },
      "source": [
        "train['text'] = train['text'].str.lower().apply(remove_stopwords).apply(alpha_num)\n",
        "test['text'] = test['text'].str.lower().apply(remove_stopwords).apply(alpha_num)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4REFzpx2ylni",
        "outputId": "e450c4e3-4590-4d3e-d1af-dc577d0457fd"
      },
      "source": [
        "#2차 불용어 불러오기\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english')) \n",
        "\n",
        "#토크나이저 및 스테머 불러오기\n",
        "tokenizer_tb = TreebankWordTokenizer()\n",
        "pst = PorterStemmer()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dY3T9U3Qylnj"
      },
      "source": [
        "#2차 불용어 처리\n",
        "tokens_trn = []\n",
        "tokens_tst = []\n",
        "\n",
        "for txt in train['text'] :\n",
        "  token = tokenizer_tb.tokenize(txt)\n",
        "  non_stopwords = [pst.stem(t) for t in token if not t in stop_words]\n",
        "  tokens_trn.append(non_stopwords)\n",
        "\n",
        "\n",
        "for txt in test['text'] :\n",
        "  token = tokenizer_tb.tokenize(txt)\n",
        "  non_stopwords = [pst.stem(t) for t in token if not t in stop_words]\n",
        "  tokens_tst.append(non_stopwords)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ty2Iwvigylnj"
      },
      "source": [
        "#2차 불용어 처리\n",
        "tokens_trn = []\n",
        "tokens_tst = []\n",
        "\n",
        "for txt in train['text'] :\n",
        "  token = tokenizer_tb.tokenize(txt)\n",
        "  tokens_trn.append(token)\n",
        "\n",
        "\n",
        "for txt in test['text'] :\n",
        "  token = tokenizer_tb.tokenize(txt)\n",
        "  tokens_tst.append(token)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJq96cqyylnj"
      },
      "source": [
        "train['text'] = tokens_trn\n",
        "test['text'] = tokens_tst"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WaSCIXVYylnj"
      },
      "source": [
        "X_train = np.array([x for x in train['text']])\n",
        "X_test = np.array([x for x in test['text']])\n",
        "y_train = np.array([x for x in train['author']])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVbWxAVNylnj"
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "word_index = tokenizer.word_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GyLEykgFylnj",
        "outputId": "6f03b746-8a68-4e39-f235-beb7709c3428"
      },
      "source": [
        "max_words = len(word_index) + 1\n",
        "print( 'unique words are : %d' % max_words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "unique words are : 46611\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPZpCgh_ylnj",
        "outputId": "b276cbf4-8946-46a7-9d21-4b182f7f616a"
      },
      "source": [
        "#단어 길이 확인\n",
        "max_length = max([len(s) for s in X_train])\n",
        "min_length = min([len(s) for s in X_train])\n",
        "mean_length = np.mean([len(s) for s in X_train])\n",
        "median_length = np.median([len(s) for s in X_train])\n",
        "\n",
        "print( 'Train Max length: %d ' % max_length)\n",
        "print( 'Train Min length: %d ' % min_length) # test에서는 7이므로 괜찮음\n",
        "print( 'Train Mean length: %d ' % mean_length)\n",
        "print( 'Train Median length: %d ' % median_length)\n",
        "\n",
        "\n",
        "max_length_tst = max([len(s) for s in X_test])\n",
        "min_length_tst = min([len(s) for s in X_test])\n",
        "mean_length_tst = np.mean([len(s) for s in X_test])\n",
        "median_length_tst = np.median([len(s) for s in X_test])\n",
        "\n",
        "print( 'Test Max length: %d ' % max_length_tst)\n",
        "print( 'Test Min length: %d ' % min_length_tst) # test에서는 7이므로 괜찮음\n",
        "print( 'Test Mean length: %d ' % mean_length_tst)\n",
        "print( 'Test Median length: %d ' % median_length_tst)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Max length: 474 \n",
            "Train Min length: 0 \n",
            "Train Mean length: 42 \n",
            "Train Median length: 22 \n",
            "Test Max length: 470 \n",
            "Test Min length: 29 \n",
            "Test Mean length: 91 \n",
            "Test Median length: 71 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4niwkfotU0V"
      },
      "source": [
        "# 모델링 및 성능평가"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "faxRwiQBy-A-"
      },
      "source": [
        "LSTM : 0.4196639302\t"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "su70BW7ky17c"
      },
      "source": [
        "#파라미터 설정\n",
        "vocab_size = 20000\n",
        "embedding_dim = 100\n",
        "max_length = 50\n",
        "padding_type='post'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XjgKULCy17d"
      },
      "source": [
        "#데이터를 sequence로 변환하고 padding\n",
        "train_sequences = tokenizer.texts_to_sequences(X_train)\n",
        "train_padded = pad_sequences(train_sequences, padding=padding_type, maxlen=max_length)\n",
        "\n",
        "test_sequences = tokenizer.texts_to_sequences(X_test)\n",
        "test_padded = pad_sequences(test_sequences, padding=padding_type, maxlen=max_length)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yd0NCe6Py17d"
      },
      "source": [
        "num_words = len(word_index)+1\n",
        "embedding_matrix = np.zeros((num_words, 100))\n",
        "\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embedding_dict.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27sRVBwzy17d"
      },
      "source": [
        "n_fold = 5\n",
        "n_class = 5\n",
        "cv = StratifiedKFold(n_splits = n_fold, shuffle = True, random_state = 42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMl2MzmCy17d"
      },
      "source": [
        "def get_model():\n",
        "    model = Sequential([\n",
        "        Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "        Bidirectional(LSTM(64, dropout= 0.2, recurrent_dropout=0.2,return_sequences=True)),\n",
        "        Bidirectional(LSTM(64, dropout= 0.2)),\n",
        "        Dense(n_class, activation='softmax')\n",
        "    ])\n",
        "    \n",
        "    model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=.01))\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4U3AFcWBy17d",
        "outputId": "586b8824-226a-427d-c2a5-69ca614c8101"
      },
      "source": [
        "p_val = np.zeros((train_padded.shape[0], 5))\n",
        "p_tst = np.zeros((test_padded.shape[0], 5))\n",
        "for i, (i_trn, i_val) in enumerate(cv.split(train_padded, y_train), 1):\n",
        "    print(f'training model for CV #{i}')\n",
        "    clf = get_model()\n",
        "    \n",
        "    es = EarlyStopping(monitor='val_loss', min_delta=0.001, patience=3,\n",
        "                       verbose=1, mode='min', baseline=None, restore_best_weights=True)\n",
        "\n",
        "    clf.fit(train_padded[i_trn], \n",
        "            to_categorical(y_train[i_trn]),\n",
        "            validation_data=(train_padded[i_val], to_categorical(y_train[i_val])),\n",
        "            epochs= 20,\n",
        "            batch_size=512,\n",
        "            callbacks=[es])\n",
        "    p_val[i_val, :] = clf.predict(train_padded[i_val])\n",
        "    p_tst += clf.predict(test_padded) / n_fold"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training model for CV #1\n",
            "WARNING:tensorflow:Layer lstm_48 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_48 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_48 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Epoch 1/20\n",
            "86/86 [==============================] - 37s 432ms/step - loss: 1.0863 - val_loss: 0.8162\n",
            "Epoch 2/20\n",
            "86/86 [==============================] - 35s 401ms/step - loss: 0.6403 - val_loss: 0.7903\n",
            "Epoch 3/20\n",
            "86/86 [==============================] - 35s 410ms/step - loss: 0.4957 - val_loss: 0.8106\n",
            "Epoch 4/20\n",
            "86/86 [==============================] - 34s 397ms/step - loss: 0.4154 - val_loss: 0.8789\n",
            "Epoch 5/20\n",
            "86/86 [==============================] - ETA: 0s - loss: 0.3620Restoring model weights from the end of the best epoch.\n",
            "86/86 [==============================] - 35s 407ms/step - loss: 0.3620 - val_loss: 0.9858\n",
            "Epoch 00005: early stopping\n",
            "training model for CV #2\n",
            "WARNING:tensorflow:Layer lstm_50 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_50 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_50 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Epoch 1/20\n",
            "86/86 [==============================] - 35s 408ms/step - loss: 1.0830 - val_loss: 0.8253\n",
            "Epoch 2/20\n",
            "86/86 [==============================] - 36s 416ms/step - loss: 0.6379 - val_loss: 0.7813\n",
            "Epoch 3/20\n",
            "86/86 [==============================] - 34s 398ms/step - loss: 0.5046 - val_loss: 0.8180\n",
            "Epoch 4/20\n",
            "86/86 [==============================] - 34s 400ms/step - loss: 0.4201 - val_loss: 0.8778\n",
            "Epoch 5/20\n",
            "86/86 [==============================] - ETA: 0s - loss: 0.3663Restoring model weights from the end of the best epoch.\n",
            "86/86 [==============================] - 35s 403ms/step - loss: 0.3663 - val_loss: 0.9231\n",
            "Epoch 00005: early stopping\n",
            "training model for CV #3\n",
            "WARNING:tensorflow:Layer lstm_52 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_52 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_52 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Epoch 1/20\n",
            "86/86 [==============================] - 35s 411ms/step - loss: 1.0800 - val_loss: 0.8205\n",
            "Epoch 2/20\n",
            "86/86 [==============================] - 34s 399ms/step - loss: 0.6522 - val_loss: 0.7839\n",
            "Epoch 3/20\n",
            "86/86 [==============================] - 35s 411ms/step - loss: 0.5078 - val_loss: 0.8286\n",
            "Epoch 4/20\n",
            "86/86 [==============================] - 34s 400ms/step - loss: 0.4236 - val_loss: 0.8825\n",
            "Epoch 5/20\n",
            "86/86 [==============================] - ETA: 0s - loss: 0.3745Restoring model weights from the end of the best epoch.\n",
            "86/86 [==============================] - 35s 403ms/step - loss: 0.3745 - val_loss: 0.9424\n",
            "Epoch 00005: early stopping\n",
            "training model for CV #4\n",
            "WARNING:tensorflow:Layer lstm_54 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_54 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_54 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Epoch 1/20\n",
            "86/86 [==============================] - 35s 409ms/step - loss: 1.0657 - val_loss: 0.8244\n",
            "Epoch 2/20\n",
            "86/86 [==============================] - 35s 402ms/step - loss: 0.6361 - val_loss: 0.7669\n",
            "Epoch 3/20\n",
            "86/86 [==============================] - 35s 405ms/step - loss: 0.4996 - val_loss: 0.8005\n",
            "Epoch 4/20\n",
            "86/86 [==============================] - 35s 408ms/step - loss: 0.4268 - val_loss: 0.8608\n",
            "Epoch 5/20\n",
            "86/86 [==============================] - ETA: 0s - loss: 0.3722Restoring model weights from the end of the best epoch.\n",
            "86/86 [==============================] - 34s 395ms/step - loss: 0.3722 - val_loss: 0.9289\n",
            "Epoch 00005: early stopping\n",
            "training model for CV #5\n",
            "WARNING:tensorflow:Layer lstm_56 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_56 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_56 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Epoch 1/20\n",
            "86/86 [==============================] - 37s 427ms/step - loss: 1.0607 - val_loss: 0.8260\n",
            "Epoch 2/20\n",
            "86/86 [==============================] - 34s 396ms/step - loss: 0.6457 - val_loss: 0.7751\n",
            "Epoch 3/20\n",
            "86/86 [==============================] - 34s 400ms/step - loss: 0.5063 - val_loss: 0.7852\n",
            "Epoch 4/20\n",
            "86/86 [==============================] - 34s 398ms/step - loss: 0.4284 - val_loss: 0.8596\n",
            "Epoch 5/20\n",
            "86/86 [==============================] - ETA: 0s - loss: 0.3726Restoring model weights from the end of the best epoch.\n",
            "86/86 [==============================] - 35s 406ms/step - loss: 0.3726 - val_loss: 0.9530\n",
            "Epoch 00005: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "nw3vXmGHy17d",
        "outputId": "3c39c2e6-a483-4794-a1af-553d6ffdf471"
      },
      "source": [
        "# submission\n",
        "sample_submission[['0','1','2','3','4']] = p_tst\n",
        "sample_submission"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.122850</td>\n",
              "      <td>0.603022</td>\n",
              "      <td>0.197693</td>\n",
              "      <td>0.065256</td>\n",
              "      <td>0.011178</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.259682</td>\n",
              "      <td>0.622593</td>\n",
              "      <td>0.008344</td>\n",
              "      <td>0.047605</td>\n",
              "      <td>0.061775</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.844489</td>\n",
              "      <td>0.044937</td>\n",
              "      <td>0.010351</td>\n",
              "      <td>0.003821</td>\n",
              "      <td>0.096402</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0.180283</td>\n",
              "      <td>0.057147</td>\n",
              "      <td>0.546468</td>\n",
              "      <td>0.003079</td>\n",
              "      <td>0.213024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0.271554</td>\n",
              "      <td>0.442475</td>\n",
              "      <td>0.065065</td>\n",
              "      <td>0.097653</td>\n",
              "      <td>0.123254</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19612</th>\n",
              "      <td>19612</td>\n",
              "      <td>0.003257</td>\n",
              "      <td>0.996643</td>\n",
              "      <td>0.000025</td>\n",
              "      <td>0.000057</td>\n",
              "      <td>0.000017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19613</th>\n",
              "      <td>19613</td>\n",
              "      <td>0.100828</td>\n",
              "      <td>0.059387</td>\n",
              "      <td>0.375514</td>\n",
              "      <td>0.050895</td>\n",
              "      <td>0.413375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19614</th>\n",
              "      <td>19614</td>\n",
              "      <td>0.011379</td>\n",
              "      <td>0.985739</td>\n",
              "      <td>0.000704</td>\n",
              "      <td>0.001420</td>\n",
              "      <td>0.000758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19615</th>\n",
              "      <td>19615</td>\n",
              "      <td>0.062077</td>\n",
              "      <td>0.496767</td>\n",
              "      <td>0.017962</td>\n",
              "      <td>0.420880</td>\n",
              "      <td>0.002314</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19616</th>\n",
              "      <td>19616</td>\n",
              "      <td>0.337100</td>\n",
              "      <td>0.033732</td>\n",
              "      <td>0.107224</td>\n",
              "      <td>0.435733</td>\n",
              "      <td>0.086211</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>19617 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       index         0         1         2         3         4\n",
              "0          0  0.122850  0.603022  0.197693  0.065256  0.011178\n",
              "1          1  0.259682  0.622593  0.008344  0.047605  0.061775\n",
              "2          2  0.844489  0.044937  0.010351  0.003821  0.096402\n",
              "3          3  0.180283  0.057147  0.546468  0.003079  0.213024\n",
              "4          4  0.271554  0.442475  0.065065  0.097653  0.123254\n",
              "...      ...       ...       ...       ...       ...       ...\n",
              "19612  19612  0.003257  0.996643  0.000025  0.000057  0.000017\n",
              "19613  19613  0.100828  0.059387  0.375514  0.050895  0.413375\n",
              "19614  19614  0.011379  0.985739  0.000704  0.001420  0.000758\n",
              "19615  19615  0.062077  0.496767  0.017962  0.420880  0.002314\n",
              "19616  19616  0.337100  0.033732  0.107224  0.435733  0.086211\n",
              "\n",
              "[19617 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    }
  ]
}